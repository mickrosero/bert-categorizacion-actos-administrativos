# ğŸ¤– Clasificador de Actos Administrativos con BERT

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![BERT](https://img.shields.io/badge/BERT-BETO-green.svg)
![spaCy](https://img.shields.io/badge/spaCy-3.0+-orange.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

## ğŸ“‹ DescripciÃ³n

Proyecto de clasificaciÃ³n automÃ¡tica de actos administrativos usando **BERT en espaÃ±ol (BETO)** con tÃ©cnicas avanzadas de **Procesamiento de Lenguaje Natural (NLP)** y limpieza de texto con **spaCy**.

Este sistema permite categorizar automÃ¡ticamente documentos administrativos en mÃºltiples categorÃ­as utilizando un modelo de transformer pre-entrenado en espaÃ±ol, fine-tuned con datos especÃ­ficos del dominio legal/administrativo.

## ğŸ¯ Objetivos

- âœ… Automatizar la clasificaciÃ³n de actos administrativos
- âœ… Reducir el tiempo de categorizaciÃ³n manual
- âœ… Mejorar la precisiÃ³n en la clasificaciÃ³n de documentos legales
- âœ… Proporcionar un sistema escalable y reutilizable
- âœ… Reclasificar documentos con categorÃ­a "OTROS" de forma inteligente

## ğŸš€ CaracterÃ­sticas Principales

### ğŸ”¹ Arquitectura HÃ­brida Local-Cloud
- **Parte 1 (Local)**: PreparaciÃ³n y limpieza de datos desde MariaDB/MySQL
- **Parte 2 (Colab)**: Entrenamiento con GPU (T4) en Google Colab

### ğŸ”¹ Procesamiento de Texto Avanzado
- **LematizaciÃ³n** con spaCy
- **EliminaciÃ³n de stopwords** en espaÃ±ol
- **NormalizaciÃ³n** de texto (minÃºsculas, puntuaciÃ³n, nÃºmeros)
- **TokenizaciÃ³n** optimizada para BERT

### ğŸ”¹ Modelo de Machine Learning
- **Modelo Base**: `dcc.uchile/bert-base-spanish-wwm-cased` (BETO)
- **Fine-tuning** para clasificaciÃ³n multi-clase
- **MÃ©tricas**: Accuracy, F1-Score (macro)
- **GestiÃ³n de clases desbalanceadas**

## ğŸ“Š CategorÃ­as de ClasificaciÃ³n

El modelo clasifica documentos en **17 categorÃ­as**, incluyendo:

1. REQUERIMIENTO DE INFORMACIÃ“N
2. REVENIDO QUÃMICO
3. ACTO URGENTE SIN INDICIOS DELICTIVOS
4. IDENTIFICACIÃ“N BIENES RETENIDOS
5. ACTO URGENTE PARA EL EJERCICIO DE LA ACCIÃ“N PRIVADA
6. MUERTE NO DELICTIVA
7. IDENTIFICACIÃ“N BIENES ABANDONADOS
8. Y mÃ¡s...

## ğŸ› ï¸ TecnologÃ­as Utilizadas

### Backend & Processing
- **Python 3.8+**
- **Transformers** (Hugging Face)
- **PyTorch** (GPU acceleration)
- **spaCy 3.0+** (`es_core_news_md`)
- **scikit-learn**

### Data Management
- **Pandas** (manipulaciÃ³n de datos)
- **PyArrow/Fastparquet** (formato Parquet)
- **SQLAlchemy** + **PyMySQL** (conexiÃ³n a bases de datos)
- **Google Drive API** (PyDrive2)

### Cloud Infrastructure
- **Google Colab** (entrenamiento con GPU T4)
- **Google Drive** (almacenamiento de modelos y datos)

## ğŸ“ Estructura del Proyecto

```
bert-categorizacion-actos-administrativos/
â”‚
â”œâ”€â”€ README.md                              # Este archivo
â”œâ”€â”€ .gitignore                             # Archivos ignorados por Git
â”‚
â”œâ”€â”€ NLP_berto_AA_COLAB_local.ipynb        # Notebook principal (hÃ­brido)
â”œâ”€â”€ NLP_berto_AA_COLAB.ipynb              # Notebook solo Colab
â”‚
â”œâ”€â”€ aa.xlsx                                # Dataset de ejemplo
â”‚
â”œâ”€â”€ models/                                # Modelos entrenados (no versionado)
â”‚   â””â”€â”€ modelo-clasificador-final/
â”‚
â”œâ”€â”€ data/                                  # Datos procesados (no versionado)
â”‚   â”œâ”€â”€ datos-procesados.parquet
â”‚   â””â”€â”€ predicciones-OTROS.csv
â”‚
â””â”€â”€ notebooks/                             # Notebooks adicionales
    â””â”€â”€ exploratory_analysis.ipynb
```

## ğŸ”§ InstalaciÃ³n

### Requisitos Previos

#### Para Parte 1 (Local)
```bash
pip install pandas pyarrow fastparquet openpyxl
pip install SQLAlchemy pymysql
pip install pydrive2
```

#### Para Parte 2 (Colab)
```bash
pip install transformers datasets accelerate torch
pip install spacy
python -m spacy download es_core_news_md
```

### ConfiguraciÃ³n de Google Drive API

1. Crear un proyecto en [Google Cloud Console](https://console.cloud.google.com/)
2. Habilitar la API de Google Drive
3. Crear credenciales OAuth 2.0
4. Descargar el archivo JSON y renombrarlo a `client_secrets.json`
5. Colocar el archivo en la misma carpeta del notebook

## ğŸ“– Uso del Sistema

### PARTE 1: PreparaciÃ³n de Datos (Kernel Local)

```python
# 1. Configurar la conexiÃ³n a tu base de datos
MARIADB_USUARIO = "tu_usuario"
MARIADB_CONTRASEÃ‘A = "tu_contraseÃ±a"
MARIADB_HOST = "192.168.x.x"
MARIADB_BDD = "tu_base_datos"

# 2. Definir las columnas
COLUMNA_TEXTO = "OBSERVACION"       # Columna con el texto
COLUMNA_ETIQUETA = "AA"             # Columna con la categorÃ­a
ETIQUETA_A_EXCLUIR = "OTROS"        # CategorÃ­a a reclasificar

# 3. Ejecutar celdas 1.1 a 1.6
# Resultado: datos-procesados.parquet en Google Drive
```

### PARTE 2: Entrenamiento (Kernel Colab con GPU)

```python
# 1. Montar Google Drive
from google.colab import drive
drive.mount('/content/drive')

# 2. Cargar el archivo Parquet
RUTA_ARCHIVO_PARQUET = '/content/drive/MyDrive/ColabData/datos-procesados.parquet'

# 3. Ejecutar celdas 2.1 a 2.9
# Resultado: Modelo entrenado + predicciones CSV
```

## ğŸ“ˆ Resultados y MÃ©tricas

### DesempeÃ±o del Modelo

| MÃ©trica | Valor |
|---------|-------|
| **Accuracy** | ~83.3% |
| **F1-Score (Macro)** | ~66.2% |
| **Epoch Ã³ptimo** | 3 |
| **Training Loss** | 0.321 |
| **Validation Loss** | 0.506 |

### Ejemplo de Predicciones

| Texto Original | PredicciÃ³n | Confianza |
|---------------|-----------|----------|
| "Se adjunta oficio sobre requerimiento..." | REQUERIMIENTO DE INFORMACIÃ“N | 98.2% |
| "Solicitud de examen mÃ©dico legal..." | ACTO URGENTE PARA EJERCICIO... | 92.5% |

## ğŸ” Pipeline de Limpieza de Texto

El sistema aplica los siguientes pasos de preprocesamiento:

```python
def limpiar_texto_spacy(texto):
    """
    1. Convertir a minÃºsculas
    2. Procesar con spaCy
    3. Eliminar stopwords (de, la, el, etc.)
    4. Eliminar puntuaciÃ³n y nÃºmeros
    5. Filtrar solo tokens alfabÃ©ticos
    6. Lematizar (corriendo â†’ correr)
    7. Retornar texto limpio
    """
    pass
```

## ğŸ“ Aplicaciones

- âœ… **Sector Legal**: ClasificaciÃ³n automÃ¡tica de documentos judiciales
- âœ… **AdministraciÃ³n PÃºblica**: CategorizaciÃ³n de trÃ¡mites y solicitudes
- âœ… **FiscalÃ­as**: OrganizaciÃ³n de actos administrativos
- âœ… **Archivos Digitales**: IndexaciÃ³n inteligente de documentos

## ğŸ¤ Contribuciones

Â¡Las contribuciones son bienvenidas! Por favor:

1. Haz un Fork del proyecto
2. Crea una rama para tu feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit tus cambios (`git commit -m 'Agregar nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Abre un Pull Request

## ğŸ“ Notas Importantes

### âš ï¸ Limitaciones

- El modelo estÃ¡ entrenado especÃ­ficamente para el dominio legal/administrativo ecuatoriano
- Requiere GPU para entrenamiento eficiente (~15-45 min en T4)
- Los datos sensibles no deben ser compartidos pÃºblicamente

### ğŸ” Consideraciones de Seguridad

- No versionar archivos con credenciales (`client_secrets.json`)
- No subir datos personales o confidenciales al repositorio
- Usar variables de entorno para informaciÃ³n sensible

## ğŸ“š Referencias

- [BETO: Spanish BERT](https://github.com/dccuchile/beto)
- [Hugging Face Transformers](https://huggingface.co/docs/transformers)
- [spaCy Documentation](https://spacy.io/)
- [Google Colab](https://colab.research.google.com/)

## ğŸ“§ Contacto

**Desarrollado por**: [Tu Nombre]
**Email**: tu.email@ejemplo.com
**GitHub**: [@mickrosero](https://github.com/mickrosero)

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.

---

â­ Si este proyecto te fue Ãºtil, Â¡no olvides darle una estrella! â­

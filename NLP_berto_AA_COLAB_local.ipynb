{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd21b98c",
   "metadata": {},
   "source": [
    "# Notebook Híbrido: (Local ➔ Colab) Clasificador de Texto\n",
    "\n",
    "## INSTRUCCIONES IMPORTANTES\n",
    "Este notebook debe ejecutarse en dos pases con dos kernels diferentes:\n",
    "\n",
    "## PASE 1 (Preparación de Datos):\n",
    "\n",
    "**Kernel:** Conecta este notebook a tu Kernel de Python Local.\n",
    "\n",
    "**Acción:** Ejecuta todas las celdas de la \"PARTE 1\" (de 1.1 a 1.5).\n",
    "\n",
    "**Resultado:** Se conectará a tu fuente de datos local (MariaDB o archivos) y creará datos_procesados.parquet.\n",
    "\n",
    "## PASE 2 (Entrenamiento en Nube):\n",
    "\n",
    "**Kernel:** Cambia el kernel de este notebook a tu Runtime de Colab (con GPU T4).\n",
    "\n",
    "**Acción:** Ejecuta todas las celdas de la \"PARTE 2\" (de 2.1 a 2.9).\n",
    "\n",
    "**Resultado:** El modelo se entrenará en la GPU de Colab y se guardarán tus predicciones localmente.\n",
    "\n",
    "------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb3de0e",
   "metadata": {},
   "source": [
    "### PARTE 1: PREPARACIÓN DE DATOS (EJECUTAR EN KERNEL LOCAL)\n",
    "\n",
    "#### Guardián de Kernel (Local)\n",
    "#### Esta celda verifica que estés en el kernel correcto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "298dcfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Verificando Kernel para la PARTE 1 ---\n",
      "Kernel LOCAL detectado. ¡Correcto!\n",
      "Usando Python en: c:\\Program Files\\Python313\\python.exe\n"
     ]
    }
   ],
   "source": [
    "# --- 1.1 Guardián de Kernel (Local) ---\n",
    "# Esta celda verifica que el kernel actual sea local y no de Colab.\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"--- Verificando Kernel para la PARTE 1 ---\")\n",
    "\n",
    "# 'sys.modules' es un diccionario de todos los módulos que han sido importados.\n",
    "# Si 'google.colab' está en ese diccionario, significa que el script corre en Colab.\n",
    "if 'google.colab' in sys.modules:\n",
    "    # Si es así, lanzamos una excepción para detener la ejecución.\n",
    "    raise Exception(\n",
    "        \"¡KERNEL INCORRECTO! \"\n",
    "        \"Esta celda (Parte 1) debe ejecutarse en un KERNEL LOCAL, no en Colab. \"\n",
    "        \"Por favor, cambie el kernel a su entorno de Python local.\"\n",
    "    )\n",
    "else:\n",
    "    # Si no, estamos en el kernel local correcto.\n",
    "    print(\"Kernel LOCAL detectado. ¡Correcto!\")\n",
    "    print(f\"Usando Python en: {sys.executable}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734487d1",
   "metadata": {},
   "source": [
    "Instalar Librerías (Local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "898fb8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asegúrate de haber instalado localmente: pandas, pyarrow, fastparquet, openpyxl, SQLAlchemy, pymysql, pydrive2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# --- 1.2 Instalar Librerías (Local) ---\n",
    "# (Asegúrate de haber ejecutado esto una vez en tu terminal local)\n",
    "!pip install pandas pyarrow fastparquet openpyxl SQLAlchemy pymysql pydrive2 -q\n",
    "print(\"Asegúrate de haber instalado localmente: pandas, pyarrow, fastparquet, openpyxl, SQLAlchemy, pymysql, pydrive2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e2e066",
   "metadata": {},
   "source": [
    "Importar Librerías (Local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09f1c78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerías locales (incluyendo PyDrive) importadas.\n"
     ]
    }
   ],
   "source": [
    "# --- 1.3 Importar Librerías (Local) ---\n",
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import create_engine # Para conectarse a bases de datos SQL\n",
    "from pydrive2.auth import GoogleAuth # Para autenticación con Google\n",
    "from pydrive2.drive import GoogleDrive # Para interactuar con Google Drive\n",
    "print(\"Librerías locales (incluyendo PyDrive) importadas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a89967",
   "metadata": {},
   "source": [
    "Configuración del Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e72cb664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuración cargada. Fuente: MARIADB\n",
      "Salida será: datos_procesados.parquet\n"
     ]
    }
   ],
   "source": [
    "# --- 1.4 CONFIGURACIÓN DEL USUARIO (El Menú) ---\n",
    "# En esta celda se define de dónde saldrán los datos y cómo se llaman las columnas.\n",
    "\n",
    "# --- A. Configuración de Columnas (Requerido) ---\n",
    "COLUMNA_TEXTO = \"OBSERVACION\"       # Columna con el texto a analizar\n",
    "COLUMNA_ETIQUETA = \"AA\"             # Columna con la categoría o 'label'\n",
    "ETIQUETA_A_EXCLUIR = \"OTROS\"        # Categoría que queremos reclasificar\n",
    "\n",
    "# --- B. Configuración de SALIDA (Requerido) ---\n",
    "# Nombre del archivo Parquet que se creará localmente y se subirá a Drive.\n",
    "RUTA_ARCHIVO_PARQUET_SALIDA = \"datos_procesados.parquet\"\n",
    "\n",
    "# --- C. CONFIGURACIÓN DE FUENTE ORIGINAL (Elige UNA) ---\n",
    "# Prioridad 1: Base de Datos. Prioridad 2: Archivos.\n",
    "# Descomenta la sección que quieras usar.\n",
    "\n",
    "# Opción 1: Base de Datos MariaDB (o MySQL) [OPCIÓN PRIORITARIA]\n",
    "#------------------------------------------------\n",
    "TIPO_FUENTE_ORIGINAL = 'MARIADB'\n",
    "RUTA_FUENTE_ORIGINAL = None # No se usa un archivo\n",
    "\n",
    "# Configuración de la conexión (se ejecutará desde tu IP local)\n",
    "MARIADB_USUARIO = \"roserom\"\n",
    "MARIADB_CONTRASENA = \"roserom\"\n",
    "MARIADB_HOST = \"192.168.152.197\" # o 127.0.0.1\n",
    "MARIADB_PUERTO = \"3306\"\n",
    "MARIADB_BDD = \"reportes\"\n",
    "\n",
    "# La consulta SQL para traer los datos.\n",
    "# (Esta consulta ahora usa espacios normales)\n",
    "CONSULTA_SQL = f\"\"\"\n",
    "    SELECT \n",
    "        * FROM aa_table\n",
    "\"\"\"\n",
    "\n",
    "# Opción 2: Archivo (Excel o CSV) [OPCIÓN SECUNDARIA]\n",
    "#------------------------------------------------\n",
    "# Descomenta una de estas líneas si NO usas MariaDB\n",
    "\n",
    "# TIPO_FUENTE_ORIGINAL = 'EXCEL'\n",
    "# RUTA_FUENTE_ORIGINAL = \"mi_archivo_excel.xlsx\" \n",
    "# NOMBRE_HOJA_EXCEL = 0 # 0 para la primera hoja, o el nombre 'Hoja1'\n",
    "\n",
    "# TIPO_FUENTE_ORIGINAL = 'CSV'\n",
    "# RUTA_FUENTE_ORIGINAL = \"SOLICITUD DE INFORMACIÓN ACTOS ADMINISTRATIVOS  corte 20251024.xlsx - ACTOS ADMINISTRATIVOS.csv\"\n",
    "# SEPARADOR_CSV = ',' \n",
    "\n",
    "#------------------------------------------------\n",
    "\n",
    "print(f\"Configuración cargada. Fuente: {TIPO_FUENTE_ORIGINAL}\")\n",
    "print(f\"Salida será: {RUTA_ARCHIVO_PARQUET_SALIDA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60edca06",
   "metadata": {},
   "source": [
    "Cargar Datos y Guardar en Parquet (Local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd5a821f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando desde la fuente: MARIADB...\n",
      "Conectando a MariaDB en 192.168.152.197...\n",
      "Datos cargados desde MariaDB.\n",
      "Columnas cargadas: ['PROVINCIA_RECEPCION', 'CANTON_RECEPCION', 'EDIFICIO_RECEPCION', 'FECHA_PS', 'DENUNCIANTE', 'USUARIO_INGRESA', 'AA', 'NUMERO_AA', 'PROVINCIA_US', 'CANTON_US', 'EDIFICIO_US', 'ESPECIALIZACION', 'FISCALIA', 'CEDULA_FISCAL', 'NOMBRE_FISCAL', 'OBSERVACION']\n",
      "Columnas requeridas verificadas.\n",
      "\n",
      "Archivo Parquet guardado localmente en: 'datos_procesados.parquet'\n",
      "Total de filas guardadas: 475207\n"
     ]
    }
   ],
   "source": [
    "# --- 1.5 Cargar y guardar en Parquet ---\n",
    "# Esta celda se conecta a la fuente de datos definida en 1.4\n",
    "# y guarda el resultado en un archivo Parquet local.\n",
    "print(f\"Cargando desde la fuente: {TIPO_FUENTE_ORIGINAL}...\")\n",
    "\n",
    "try:\n",
    "    # CASE 1: Fuente es MariaDB (¡Prioridad!)\n",
    "    if TIPO_FUENTE_ORIGINAL == 'MARIADB':\n",
    "        print(f\"Conectando a MariaDB en {MARIADB_HOST}...\")\n",
    "        # Se crea la cadena de conexión estándar de SQLAlchemy\n",
    "        CADENA_CONEXION_DB = (\n",
    "            f\"mysql+pymysql://{MARIADB_USUARIO}:{MARIADB_CONTRASENA}\"\n",
    "            f\"@{MARIADB_HOST}:{MARIADB_PUERTO}/{MARIADB_BDD}\"\n",
    "        )\n",
    "        engine = create_engine(CADENA_CONEXION_DB)\n",
    "        # 'with' asegura que la conexión se cierre automáticamente\n",
    "        with engine.connect() as connection:\n",
    "            df_origen = pd.read_sql(CONSULTA_SQL, connection)\n",
    "        print(f\"Datos cargados desde MariaDB.\")\n",
    "\n",
    "    # CASE 2: Fuente es Excel\n",
    "    elif TIPO_FUENTE_ORIGINAL == 'EXCEL':\n",
    "        if not os.path.exists(RUTA_FUENTE_ORIGINAL):\n",
    "            raise FileNotFoundError(f\"Archivo Excel no encontrado: {RUTA_FUENTE_ORIGINAL}\")\n",
    "        df_origen = pd.read_excel(RUTA_FUENTE_ORIGINAL, sheet_name=NOMBRE_HOJA_EXCEL)\n",
    "        print(\"Datos cargados desde Excel.\")\n",
    "\n",
    "    # CASE 3: Fuente es CSV\n",
    "    elif TIPO_FUENTE_ORIGINAL == 'CSV':\n",
    "        if not os.path.exists(RUTA_FUENTE_ORIGINAL):\n",
    "            raise FileNotFoundError(f\"Archivo CSV no encontrado: {RUTA_FUENTE_ORIGINAL}\")\n",
    "        try:\n",
    "            df_origen = pd.read_csv(RUTA_FUENTE_ORIGINAL, sep=SEPARADOR_CSV)\n",
    "        except UnicodeDecodeError:\n",
    "            print(\"Error de UTF-8, reintentando con encoding 'latin1'...\")\n",
    "            df_origen = pd.read_csv(RUTA_FUENTE_ORIGINAL, sep=SEPARADOR_CSV, encoding='latin1')\n",
    "        print(\"Datos cargados desde CSV.\")\n",
    "    \n",
    "    # Opción por defecto: Error\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"TIPO_FUENTE_ORIGINAL ('{TIPO_FUENTE_ORIGINAL}') no reconocido. \"\n",
    "            f\"Valores válidos: 'MARIADB', 'EXCEL', 'CSV'.\"\n",
    "        )\n",
    "\n",
    "    # --- Verificación y guardado en Parquet ---\n",
    "    print(f\"Columnas cargadas: {df_origen.columns.tolist()}\")\n",
    "    \n",
    "    # Verificación crucial: ¿Existen las columnas que el usuario definió?\n",
    "    if COLUMNA_TEXTO not in df_origen.columns or COLUMNA_ETIQUETA not in df_origen.columns:\n",
    "        raise ValueError(f\"¡ERROR! El DataFrame cargado NO contiene las columnas especificadas: '{COLUMNA_TEXTO}' y '{COLUMNA_ETIQUETA}'.\")\n",
    "    else:\n",
    "        print(\"Columnas requeridas verificadas.\")\n",
    "        # Guarda el DataFrame completo en formato Parquet\n",
    "        df_origen.to_parquet(RUTA_ARCHIVO_PARQUET_SALIDA, index=False)\n",
    "        print(f\"\\nArchivo Parquet guardado localmente en: '{RUTA_ARCHIVO_PARQUET_SALIDA}'\")\n",
    "        print(f\"Total de filas guardadas: {len(df_origen)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error fatal al cargar los datos: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5969df",
   "metadata": {},
   "source": [
    "Subir Parquet a Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39a75901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando autenticación con Google Drive...\n",
      "Autenticación exitosa.\n",
      "Subiendo 'datos_procesados.parquet' a Google Drive...\n",
      "Buscando en la carpeta especificada (ID: 1xmrejogq4heB9AkqeK1xhIJEOJhtH-M6)...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'drive' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     65\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBuscando en la raíz de \u001b[39m\u001b[33m'\u001b[39m\u001b[33mMi Unidad\u001b[39m\u001b[33m'\u001b[39m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# 1. Busca si el archivo ya existe para reemplazarlo\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m file_list = \u001b[43mdrive\u001b[49m.ListFile(file_metadata).GetList()\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file_list:\n\u001b[32m     72\u001b[39m     \u001b[38;5;66;03m# Si existe, toma el primero y lo usará para sobrescribir\u001b[39;00m\n\u001b[32m     73\u001b[39m     file_drive = file_list[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'drive' is not defined"
     ]
    }
   ],
   "source": [
    "# --- 1.6 Subir archivo Parquet a Google Drive ---\n",
    "# Esta celda toma el archivo Parquet local y lo sube a Google Drive.\n",
    "\n",
    "# --- ADVERTENCIA DE CONFIGURACIÓN ---\n",
    "#\n",
    "# ¡IMPORTANTE! Antes de ejecutar esta celda, debes:\n",
    "# 1. Haber seguido los pasos para crear credenciales en Google Cloud.\n",
    "# 2. Haber descargado el archivo JSON de credenciales.\n",
    "# 3. Haber renombrado ese archivo a 'client_secrets.json'.\n",
    "# 4. Haber colocado el archivo 'client_secrets.json' EN LA MISMA CARPETA\n",
    "#    que este notebook.\n",
    "#\n",
    "# Si no lo has hecho, esta celda fallará con un error 'FileNotFoundError'.\n",
    "#\n",
    "# --- FIN DE LA ADVERTENCIA ---\n",
    "\n",
    "print(\"Iniciando autenticación con Google Drive...\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Autenticación\n",
    "gauth = GoogleAuth()\n",
    "# Ajuste: Especificar la ruta al archivo de secretos.\n",
    "# Como el archivo está un nivel arriba del notebook, usamos '../'.\n",
    "# Esto resuelve el error 'FileNotFoundError'.\n",
    "gauth.settings['client_config_file'] = '../client_secrets.json'\n",
    "\n",
    "# Esto buscará 'client_secrets.json' en esta carpeta.\n",
    "# Si no existen credenciales guardadas (settings.yaml),\n",
    "# abrirá tu navegador para que inicies sesión la primera vez.\n",
    "\n",
    "\n",
    "\n",
    "print(\"Autenticación exitosa.\")\n",
    "\n",
    "# --- Opcional: Especificar una carpeta de Google Drive ---\n",
    "# 1. Ve a Google Drive en tu navegador.\n",
    "# 2. Entra en la carpeta donde quieres guardar los archivos.\n",
    "# 3. Copia la última parte de la URL.\n",
    "#    Ejemplo URL: https://drive.google.com/drive/folders/1xmrejogq4heB9AkqeK1xhIJEOJhtH-M6?usp=drive_link\n",
    "#    El ID es '1xmrejogq4heB9AkqeK1xhIJEOJhtH-M6'\n",
    "# 4. Descomenta la siguiente línea y pega tu ID:\n",
    "ID_CARPETA_DRIVE = \"1xmrejogq4heB9AkqeK1xhIJEOJhtH-M6\" # Corregido: Se eliminó '?usp=drive_link'\n",
    "\n",
    "# --- Subida del archivo ---\n",
    "print(f\"Subiendo '{RUTA_ARCHIVO_PARQUET_SALIDA}' a Google Drive...\")\n",
    "\n",
    "# Preparamos los metadatos para la búsqueda/creación\n",
    "file_metadata = {\n",
    "    'title': RUTA_ARCHIVO_PARQUET_SALIDA,\n",
    "    'trashed': False\n",
    "}\n",
    "\n",
    "# Si definiste un ID de carpeta, lo añadimos a los metadatos\n",
    "if 'ID_CARPETA_DRIVE' in locals():\n",
    "    # 'locals()' es un diccionario de todas las variables locales definidas\n",
    "    # Esto comprueba si la variable 'ID_CARPETA_DRIVE' existe\n",
    "    file_metadata['parents'] = [{'id': ID_CARPETA_DRIVE}]\n",
    "    print(f\"Buscando en la carpeta especificada (ID: {ID_CARPETA_DRIVE})...\")\n",
    "else:\n",
    "    # Si no, busca solo en la raíz \"Mi Unidad\"\n",
    "    # 'root' es el alias de Google Drive para la carpeta raíz\n",
    "    file_metadata['q'] = \"'root' in parents\"\n",
    "    print(\"Buscando en la raíz de 'Mi Unidad'...\")\n",
    "\n",
    "\n",
    "# 1. Busca si el archivo ya existe para reemplazarlo\n",
    "file_list = drive.ListFile(file_metadata).GetList()\n",
    "\n",
    "if file_list:\n",
    "    # Si existe, toma el primero y lo usará para sobrescribir\n",
    "    file_drive = file_list[0]\n",
    "    print(f\"Archivo existente encontrado. Reemplazando '{file_drive['title']}'...\")\n",
    "else:\n",
    "    # Si no existe, crea un nuevo objeto de archivo\n",
    "    # (quitamos 'q' y 'trashed' que solo son para búsqueda)\n",
    "    create_metadata = {'title': RUTA_ARCHIVO_PARQUET_SALIDA}\n",
    "    if 'ID_CARPETA_DRIVE' in locals():\n",
    "        create_metadata['parents'] = [{'id': ID_CARPETA_DRIVE}]\n",
    "        \n",
    "    file_drive = drive.CreateFile(create_metadata)\n",
    "    print(f\"Archivo no encontrado. Creando nuevo archivo en Google Drive...\")\n",
    "\n",
    "# 2. Asigna el contenido del archivo local y sube\n",
    "file_drive.SetContentFile(RUTA_ARCHIVO_PARQUET_SALIDA)\n",
    "file_drive.Upload()\n",
    "\n",
    "print(\"¡ÉXITO! Archivo subido/reemplazado en Google Drive.\")\n",
    "print(\"\\n--- PARTE 1 COMPLETADA ---\")\n",
    "print(\"Ahora, cambie el Kernel de este notebook a COLAB (con GPU) y ejecute las celdas de la PARTE 2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c608a611",
   "metadata": {},
   "source": [
    "### PARTE 2: ENTRENAMIENTO (EJECUTAR EN KERNEL COLAB+GPU)\n",
    "\n",
    "### Guardián de Kernel (Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e235a7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Verificando Kernel para la PARTE 2 ---\n",
      "Kernel de Colab detectado. ¡Correcto!\n",
      "GPU de Colab activa: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "print(\"--- Verificando Kernel para la PARTE 2 ---\")\n",
    "# Esta vez, verificamos que 'google.colab' SÍ esté en los módulos\n",
    "if 'google.colab' in sys.modules:\n",
    "    print(\"Kernel de Colab detectado. ¡Correcto!\")\n",
    "    \n",
    "    # Verificación secundaria: ¿Está la GPU activa?\n",
    "    if not torch.cuda.is_available():\n",
    "        raise Exception(\n",
    "            \"¡GPU NO DETECTADA! \"\n",
    "            \"Estás en Colab, pero la GPU no está activa. \"\n",
    "            \"Ve a 'Entorno de ejecución' > 'Cambiar tipo de entorno de ejecución' y selecciona 'T4 GPU'.\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"GPU de Colab activa: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    # Si no estamos en Colab, detenemos la ejecución\n",
    "    raise Exception(\n",
    "        \"¡KERNEL INCORRECTO! \"\n",
    "        \"Esta celda (Parte 2) debe ejecutarse en un KERNEL DE COLAB (con GPU). \"\n",
    "        \"Por favor, cambie el kernel.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab88a19",
   "metadata": {},
   "source": [
    "Instalar Librerías (en Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c080195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2.2 Instalar las librerías necesarias en el runtime de Colab ---\n",
    "# El '!' ejecuta comandos de terminal en la máquina virtual de Colab\n",
    "# '-q' significa 'quiet' (silencioso), para no llenar la salida con texto\n",
    "!pip install transformers datasets accelerate torch pandas scikit-learn -q\n",
    "!pip install pyarrow fastparquet -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76cda7a",
   "metadata": {},
   "source": [
    "Importar Librerías (Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8255b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerías de Colab importadas.\n"
     ]
    }
   ],
   "source": [
    "# --- 2.3 Importar Librerías (Colab) ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments \n",
    ")\n",
    "from datasets import Dataset\n",
    "\n",
    "# Definimos el dispositivo de cómputo como 'cuda' (la GPU)\n",
    "device = torch.device(\"cuda\") \n",
    "print(\"Librerías de Colab importadas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab390ff",
   "metadata": {},
   "source": [
    "Configuración y Carga de Parquet (Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c6e62f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "mount failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-556132399.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#    Esto nos dará acceso permanente a los archivos en tu Drive.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 2. RUTA_ARCHIVO_PARQUET (¡IMPORTANTE!)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         )\n\u001b[0;32m--> 272\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: mount failed"
     ]
    }
   ],
   "source": [
    "# --- 2.4 Configuración y Carga de Datos (Colab) ---\n",
    "\n",
    "# 1. MONTAR GOOGLE DRIVE (Método robusto para Colab)\n",
    "#    Esto solicitará autenticación y montará tu Drive en '/content/drive'.\n",
    "from google.colab import auth\n",
    "from google.colab import drive\n",
    "\n",
    "auth.authenticate_user()\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "\n",
    "# 2. RUTA_ARCHIVO_PARQUET (¡IMPORTANTE!)\n",
    "#    Asegúrate de subir 'datos_procesados.parquet' a esta carpeta en tu Google Drive.\n",
    "#    Puedes crear la carpeta 'Colab_Data' o cambiar la ruta a donde prefieras.\n",
    "RUTA_ARCHIVO_PARQUET = \"/content/drive/MyDrive/Colab_Data/datos_procesados.parquet\"\n",
    "\n",
    "# 3. NOMBRES DE COLUMNAS (deben coincidir con la Parte 1)\n",
    "COLUMNA_TEXTO = \"OBSERVACION\"\n",
    "COLUMNA_ETIQUETA = \"AA\"\n",
    "ETIQUETA_A_EXCLUIR = \"OTROS\"\n",
    "\n",
    "# 4. CONFIGURACIÓN DEL MODELO\n",
    "MODELO_BETO = \"dcc.uachile/bert-base-spanish-wwm-cased\" # Modelo BERT pre-entrenado para español\n",
    "MODELO_FINAL_NOMBRE = \"modelo_clasificador_final\" # Carpeta donde se guardará el modelo\n",
    "SALIDA_PREDICCIONES = f\"predicciones_{ETIQUETA_A_EXCLUIR}.csv\" # Nombre del archivo final\n",
    "\n",
    "# --- Cargar datos desde Google Drive ---\n",
    "print(f\"Buscando el archivo en Google Drive: '{RUTA_ARCHIVO_PARQUET}'...\")\n",
    "\n",
    "if not os.path.exists(RUTA_ARCHIVO_PARQUET):\n",
    "    raise FileNotFoundError(f\"¡ARCHIVO NO ENCONTRADO! Asegúrate de haber subido 'datos_procesados.parquet' a la ruta correcta en tu Google Drive.\")\n",
    "else:\n",
    "    print(\"¡Archivo encontrado en Google Drive!\")\n",
    "\n",
    "# Leer el archivo Parquet en un DataFrame de Pandas\n",
    "df = pd.read_parquet(RUTA_ARCHIVO_PARQUET)\n",
    "print(\"¡Datos cargados exitosamente desde Parquet!\")\n",
    "print(f\"Total de filas: {len(df)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
